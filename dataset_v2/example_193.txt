## func.py

```python
import torch
import torch.nn.functional as F

def quantized_bucketing_with_gradient_clipping(input_tensor: torch.Tensor, buckets: list,
                                                gradient_clip_value: float = 1.0) -> torch.Tensor:
    """
    Performs quantized bucketing with gradient clipping.

    Args:
        input_tensor (torch.Tensor): Input tensor.
        buckets (list): List of bucket boundaries.
        gradient_clip_value (float): Maximum value for gradient clipping. Defaults to 1.0.

    Returns:
        torch.Tensor: Quantized and bucketized output tensor.
    """

    # Convert input to int8
    input_int8 = input_tensor.to(torch.int8)

    # Bucketize
    output_int8 = torch.bucketize(input_int8, torch.tensor(buckets, dtype=torch.int8))

    # Convert back to float32 for gradient clipping
    output_fp32 = output_int8.to(torch.float32)

    # Apply hardtanh with gradient clipping
    output_fp32 = F.hardtanh(output_fp32, min_val=-gradient_clip_value, max_val=gradient_clip_value)

    # Convert back to int8 for output
    output_int8 = output_fp32.to(torch.int8)

    return output_int8

function_signature = {
    "name": "quantized_bucketing_with_gradient_clipping",
    "inputs": [
        ((1,), torch.float32),
        ([], torch.int32)
    ],
    "outputs": [
        ((1,), torch.int8),
    ]
}
```

## func.cu

```c++
#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <device_launch_parameters.h>
#include <math.h>
#include <stdarg.h> 

// Helper function for int8 hardtanh
__device__ __forceinline__ int8_t int8_hardtanh(int8_t x, int8_t min_val, int8_t max_val) {
    return (x < min_val) ? min_val : ((x > max_val) ? max_val : x);
}

__global__ void quantized_bucketing_with_gradient_clipping_kernel(const float* input, const int* buckets, int* output, 
                                                                 int size, int num_buckets, float gradient_clip_value) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        int8_t input_int8 = __int_as_int8(input[idx]); 
        int bucket_idx = 0;
        
        // Find the correct bucket
        for (int i = 0; i < num_buckets; i++) {
            if (input_int8 <= buckets[i]) {
                bucket_idx = i;
                break;
            }
        }

        // Hardtanh with gradient clipping
        int8_t clipped_value = int8_hardtanh(bucket_idx, __int_as_int8(-gradient_clip_value), __int_as_int8(gradient_clip_value));

        output[idx] = clipped_value;
    }
}

extern "C" {

void quantized_bucketing_with_gradient_clipping(int num_args, ...) {
    va_list args;
    va_start(args, num_args);

    // Extract input tensor
    const float* input = va_arg(args, const float*);
    int input_size = va_arg(args, int);

    // Extract buckets list
    const int* buckets = va_arg(args, const int*);
    int num_buckets = va_arg(args, int);

    // Extract gradient clip value
    float gradient_clip_value = va_arg(args, double);

    // Extract output tensor
    int* output = va_arg(args, int*);

    va_end(args);

    // Allocate device memory
    int *d_buckets, *d_output;
    cudaMalloc(&d_buckets, num_buckets * sizeof(int));
    cudaMalloc(&d_output, input_size * sizeof(int));

    // Copy data to device
    cudaMemcpy(d_buckets, buckets, num_buckets * sizeof(int), cudaMemcpyHostToDevice);

    // Launch kernel
    dim3 threadsPerBlock(256);
    dim3 numBlocks((input_size + threadsPerBlock.x - 1) / threadsPerBlock.x);
    quantized_bucketing_with_gradient_clipping_kernel<<<numBlocks, threadsPerBlock>>>(
        input, d_buckets, d_output, input_size, num_buckets, gradient_clip_value
    );

    // Copy result back to host
    cudaMemcpy(output, d_output, input_size * sizeof(int), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_buckets);
    cudaFree(d_output);
}

} // extern "C"
```