## func.py

```python
import torch
import torch.fft
import numpy as np

def pruned_conv1d_fft(input_tensor: torch.Tensor, weight: torch.Tensor, mask: torch.Tensor) -> torch.Tensor:
    """
    Performs a 1D convolution using FFT with model pruning applied.
    
    Args:
        input_tensor: Input tensor of shape (batch_size, in_channels, input_length).
        weight: Convolutional kernel of shape (out_channels, in_channels, kernel_size).
        mask: Pruning mask tensor of shape (out_channels, in_channels, kernel_size), 
              where 1 indicates a connection is kept and 0 indicates it's pruned.

    Returns:
        Output tensor of shape (batch_size, out_channels, output_length).
    """
    batch_size, in_channels, input_length = input_tensor.size()
    out_channels, _, kernel_size = weight.size()
    
    # Apply pruning mask
    weight_pruned = weight * mask
    
    # Pad input for convolution
    padding = (kernel_size - 1) // 2
    input_padded = torch.nn.functional.pad(input_tensor, (padding, padding), 'constant', 0)
    
    # Calculate output length
    output_length = input_length + kernel_size - 1
    
    # Perform convolution using FFT
    output = torch.zeros((batch_size, out_channels, output_length), dtype=torch.float32, device=input_tensor.device)
    for b in range(batch_size):
        for o in range(out_channels):
            for i in range(in_channels):
                # Only process if the connection is not pruned
                if mask[o, i, :].any():
                    # Convolve using FFT
                    output[b, o, :] += torch.fft.irfft(
                        torch.fft.rfft(input_padded[b, i, :], n=output_length) * torch.fft.rfft(weight_pruned[o, i, :], n=output_length),
                        n=output_length
                    )
    
    return output

function_signature = {
    "name": "pruned_conv1d_fft",
    "inputs": [
        ((1, 4, 10), torch.float32),
        ((3, 4, 3), torch.float32),
        ((3, 4, 3), torch.bool)
    ],
    "outputs": [
        ((1, 3, 12), torch.float32),
    ]
}
```

## func.cu

```c++
#include <cuda_runtime.h>
#include <device_launch_parameters.h>
#include <math.h>
#include <complex>
#include <stdarg.h>

#define PI 3.14159265358979323846

// Helper function to convert float to complex<float>
__device__ __forceinline__ std::complex<float> float_to_complex(float f) {
    return std::complex<float>(f, 0.0f);
}

// Helper function to convert complex<float> to float
__device__ __forceinline__ float complex_to_float(const std::complex<float>& c) {
    return c.real();
}

// CUDA kernel for FFT-based convolution
__global__ void pruned_conv1d_fft_kernel(const float* input_tensor, const float* weight, const bool* mask,
                                            float* output, int batch_size, int in_channels, int input_length,
                                            int out_channels, int kernel_size, int output_length) {
    int b = blockIdx.x * blockDim.x + threadIdx.x;
    int o = blockIdx.y * blockDim.y + threadIdx.y;

    if (b < batch_size && o < out_channels) {
        std::complex<float> sum = 0.0f;
        for (int i = 0; i < in_channels; ++i) {
            if (mask[o * in_channels * kernel_size + i * kernel_size]) {
                for (int k = 0; k < kernel_size; ++k) {
                    sum += float_to_complex(input_tensor[(b * in_channels + i) * input_length + k]) *
                          float_to_complex(weight[(o * in_channels + i) * kernel_size + k]);
                }
            }
        }

        // Calculate the output for each thread
        for (int n = 0; n < output_length; ++n) {
            float angle = 2.0f * PI * n * (o * in_channels + i) / output_length;
            sum *= std::complex<float>(cos(angle), sin(angle));
        }

        output[(b * out_channels + o) * output_length + n] = complex_to_float(sum);
    }
}

extern "C" {
void pruned_conv1d_fft(int num_args, ...) {
    va_list args;
    va_start(args, num_args);

    // Extract input tensor
    const float* input_tensor = va_arg(args, const float*);
    int input_tensor_dim0 = va_arg(args, int);
    int input_tensor_dim1 = va_arg(args, int);
    int input_tensor_dim2 = va_arg(args, int);

    // Extract weight tensor
    const float* weight = va_arg(args, const float*);
    int weight_dim0 = va_arg(args, int);
    int weight_dim1 = va_arg(args, int);
    int weight_dim2 = va_arg(args, int);

    // Extract mask tensor
    const bool* mask = va_arg(args, const bool*);

    // Extract output tensor (assuming it's preallocated)
    float* output = va_arg(args, float*);

    va_end(args);

    int batch_size = input_tensor_dim0;
    int in_channels = input_tensor_dim1;
    int input_length = input_tensor_dim2;
    int out_channels = weight_dim0;
    int kernel_size = weight_dim2;
    int output_length = input_length + kernel_size - 1;

    // Allocate device memory
    float *d_input, *d_weight, *d_output;
    bool *d_mask;
    cudaMalloc(&d_input, batch_size * in_channels * input_length * sizeof(float));
    cudaMalloc(&d_weight, out_channels * in_channels * kernel_size * sizeof(float));
    cudaMalloc(&d_output, batch_size * out_channels * output_length * sizeof(float));
    cudaMalloc(&d_mask, out_channels * in_channels * kernel_size * sizeof(bool));

    // Copy input data to device
    cudaMemcpy(d_input, input_tensor, batch_size * in_channels * input_length * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_weight, weight, out_channels * in_channels * kernel_size * sizeof(float), cudaMemcpyHostToDevice);
    cudaMemcpy(d_mask, mask, out_channels * in_channels * kernel_size * sizeof(bool), cudaMemcpyHostToDevice);

    // Launch kernel
    dim3 threadsPerBlock(32, 32);
    dim3 numBlocks((batch_size + threadsPerBlock.x - 1) / threadsPerBlock.x,
                   (out_channels + threadsPerBlock.y - 1) / threadsPerBlock.y);

    pruned_conv1d_fft_kernel<<<numBlocks, threadsPerBlock>>>(
        d_input, d_weight, d_mask, d_output, batch_size, in_channels, input_length,
        out_channels, kernel_size, output_length
    );

    // Copy result back to host
    cudaMemcpy(output, d_output, batch_size * out_channels * output_length * sizeof(float), cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_input);
    cudaFree(d_weight);
    cudaFree(d_output);
    cudaFree(d_mask);
}

} // extern "C"
```